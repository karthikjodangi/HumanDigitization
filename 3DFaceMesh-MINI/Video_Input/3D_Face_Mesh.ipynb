{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Google Collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clear Temporary Folder which we will use further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearMesh():\n",
    "        folder_path = \"mesh_frames\"\n",
    "\n",
    "        files = glob.glob(os.path.join(folder_path, '*'))\n",
    "\n",
    "        for file in files:\n",
    "                os.remove(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mediapipe object\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh()\n",
    "\n",
    "#video file\n",
    "input_video_path = #enter the path of your video input\n",
    "\n",
    "#input video object\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "#input video properties\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "fps = int(cap.get(5))\n",
    "\n",
    "\n",
    "#temporary folder to store frames\n",
    "output_folder = 'mesh_frames'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#processing each frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Video processing complete.')\n",
    "        break\n",
    "\n",
    "    #mediapipe requires RGB format\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #landmarks acquired in results\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    #if no face detected\n",
    "    if not results.multi_face_landmarks:\n",
    "        continue\n",
    "\n",
    "    #extracting landmarks\n",
    "    landmarks_3d = []\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                x, y, z = landmark.x, landmark.y, landmark.z\n",
    "                landmarks_3d.append((x, y, z))\n",
    "\n",
    "    landmarks_3d = np.array(landmarks_3d)\n",
    "\n",
    "    #Delaunay triangulation\n",
    "    triangulation = Delaunay(landmarks_3d[:, :2])\n",
    "\n",
    "    #naming the frame to save into temporary folder\n",
    "    frame_filename = f\"{output_folder}/frame_{int(cap.get(cv2.CAP_PROP_POS_FRAMES))}.png\"\n",
    "\n",
    "    # 3D surface plot\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "    # triangulation in 3D\n",
    "    ax.plot_trisurf(landmarks_3d[:, 0], landmarks_3d[:, 1], landmarks_3d[:, 2],\n",
    "                    triangles=triangulation.simplices, color='lightblue',edgecolor='none', antialiased=False, shade=150) \n",
    "\n",
    "    ax.set_title('3D triangulated mesh')\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "\n",
    "\n",
    "    ax.view_init(elev=-90, azim=-90)\n",
    "\n",
    "    # image with facial keypoints\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(frame_rgb)\n",
    "    ax2.set_title('Face input')\n",
    "    ax2.axis('off')\n",
    "    plt.axis('off')\n",
    "    ax.set_axis_off()\n",
    "    fig.savefig(frame_filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_folder = 'mesh_frames'\n",
    "\n",
    "\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg'))]\n",
    "image_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "\n",
    "first_image = cv2.imread(os.path.join(input_folder, image_files[0]))\n",
    "height, width, _ = first_image.shape\n",
    "\n",
    "\n",
    "output_video_path = 'output_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = 24\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    frame = cv2.imread(image_path)\n",
    "    out.write(frame)\n",
    "\n",
    "\n",
    "out.release()\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(output_video_path)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video playback complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

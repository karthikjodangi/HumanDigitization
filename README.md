"Human to 3D Avatar Retargeting (Face Only; Facial Expressions and Deformations)," focuses on transferring human facial expressions to 3D avatars. It explores various methodologies, including Delaunay Triangulation, Mediapipe Canonical Face Model, and Basel Face Model. The project emphasizes the balance between precision and real-time processing, where the Basel Face Model excels in accuracy but is slower, while the Mediapipe model offers faster processing, making it ideal for real-time applications. This work has significant implications for enhancing user experiences in video games, social VR, and visual storytelling.

"Generate 3D Stylized Character Expressions from Humans," aims to streamline the animation process by automating the generation of stylized 3D character expressions using human facial inputs. By training a model with the Basel Face Model, the project effectively reduces the time and expertise needed to create expressive and lifelike animations. This approach not only enhances the efficiency of character animation in video games and movies but also ensures high-quality, stylized outputs that improve the overall user experience.

Results:
![mini](3DFaceMesh-MINI/results.png)
![minor](StylizedCharacter-MINOR/results.png)
